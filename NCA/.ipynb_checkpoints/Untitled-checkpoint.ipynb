{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e26413",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-68f6e5e028ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import PIL.Image, PIL.ImageDraw\n",
    "import base64\n",
    "import zipfile\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f013023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3366e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from IPython.display import Image, HTML, clear_output\n",
    "\n",
    "\n",
    "\n",
    "def np2pil(a):\n",
    "  if a.dtype in [np.float32, np.float64]:\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "  return PIL.Image.fromarray(a)\n",
    "\n",
    "def imwrite(f, a, fmt=None):\n",
    "  a = np.asarray(a)\n",
    "  if isinstance(f, str):\n",
    "    fmt = f.rsplit('.', 1)[-1].lower()\n",
    "    if fmt == 'jpg':\n",
    "      fmt = 'jpeg'\n",
    "    f = open(f, 'wb')\n",
    "  np2pil(a).save(f, fmt, quality=95)\n",
    "\n",
    "def imencode(a, fmt='jpeg'):\n",
    "  a = np.asarray(a)\n",
    "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
    "    fmt = 'png'\n",
    "  f = io.BytesIO()\n",
    "  imwrite(f, a, fmt)\n",
    "  return f.getvalue()\n",
    "\n",
    "def im2url(a, fmt='jpeg'):\n",
    "  encoded = imencode(a, fmt)\n",
    "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
    "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
    "\n",
    "def imshow(a, fmt='jpeg'):\n",
    "  display(Image(data=imencode(a, fmt)))\n",
    "\n",
    "def tile2d(a, w=None):\n",
    "  a = np.asarray(a)\n",
    "  if w is None:\n",
    "    w = int(np.ceil(np.sqrt(len(a))))\n",
    "  th, tw = a.shape[1:3]\n",
    "  pad = (w-len(a))%w\n",
    "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
    "  h = len(a)//w\n",
    "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
    "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
    "  return a\n",
    "\n",
    "def zoom(img, scale=4):\n",
    "  img = np.repeat(img, scale, 0)\n",
    "  img = np.repeat(img, scale, 1)\n",
    "  return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1f77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cellular Automata Parameters\n",
    "CHANNEL_N = 16        # Number of CA state channels\n",
    "TARGET_PADDING = 16   # Number of pixels used to pad the target image border\n",
    "TARGET_SIZE = 40\n",
    "BATCH_SIZE = 2\n",
    "POOL_SIZE = 1024\n",
    "CELL_FIRE_RATE = 0.5\n",
    "\n",
    "TARGET_EMOJI = \"ðŸ¦Ž\" #@param {type:\"string\"}\n",
    "\n",
    "EXPERIMENT_TYPE = \"Regenerating\" #@param [\"Growing\", \"Persistent\", \"Regenerating\"]\n",
    "EXPERIMENT_MAP = {\"Growing\":0, \"Persistent\":1, \"Regenerating\":2}\n",
    "EXPERIMENT_N = EXPERIMENT_MAP[EXPERIMENT_TYPE]\n",
    "\n",
    "USE_PATTERN_POOL = [0, 1, 1][EXPERIMENT_N]\n",
    "DAMAGE_N = [0, 0, 3][EXPERIMENT_N]  # Number of patterns to damage in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eade20c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method CAModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x0000018813BEB5E0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method CAModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x0000018813BEB5E0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method CAModel.perceive of <tensorflow.python.eager.function.TfMethodTarget object at 0x0000018813CC16D0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method CAModel.perceive of <tensorflow.python.eager.function.TfMethodTarget object at 0x0000018813CC16D0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (1, 3, 3, 128)            6272      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (1, 3, 3, 16)             2064      \n",
      "=================================================================\n",
      "Total params: 8,336\n",
      "Trainable params: 8,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#@title CA Model and Utilities\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "def load_image(url, max_size=TARGET_SIZE):\n",
    "  r = requests.get(url)\n",
    "  img = PIL.Image.open(io.BytesIO(r.content))\n",
    "  img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
    "  img = np.float32(img)/255.0\n",
    "  # premultiply RGB by Alpha\n",
    "  img[..., :3] *= img[..., 3:]\n",
    "  return img\n",
    "\n",
    "def load_emoji(emoji):\n",
    "  code = hex(ord(emoji))[2:].lower()\n",
    "  url = 'https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
    "  return load_image(url)\n",
    "\n",
    "\n",
    "def to_rgba(x):\n",
    "  return x[..., :4]\n",
    "\n",
    "def to_alpha(x):\n",
    "  return tf.clip_by_value(x[..., 3:4], 0.0, 1.0)\n",
    "\n",
    "def to_rgb(x):\n",
    "  # assume rgb premultiplied by alpha\n",
    "  rgb, a = x[..., :3], to_alpha(x)\n",
    "  return 1.0-a+rgb\n",
    "\n",
    "def get_living_mask(x):\n",
    "  alpha = x[:, :, :, 3:4]\n",
    "  return tf.nn.max_pool2d(alpha, 3, [1, 1, 1, 1], 'SAME') > 0.1\n",
    "\n",
    "def make_seed(size, n=1):\n",
    "  x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
    "  x[:, size//2, size//2, 3:] = 1.0\n",
    "  return x\n",
    "\n",
    "\n",
    "class CAModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
    "    super().__init__()\n",
    "    self.channel_n = channel_n\n",
    "    self.fire_rate = fire_rate\n",
    "\n",
    "    self.dmodel = tf.keras.Sequential([\n",
    "          Conv2D(128, 1, activation=tf.nn.relu),\n",
    "          Conv2D(self.channel_n, 1, activation=None,\n",
    "              kernel_initializer=tf.zeros_initializer),\n",
    "    ])\n",
    "\n",
    "    self(tf.zeros([1, 3, 3, channel_n]))  # dummy call to build the model\n",
    "\n",
    "  @tf.function\n",
    "  def perceive(self, x, angle=0.0):\n",
    "    identify = np.float32([0, 1, 0])\n",
    "    identify = np.outer(identify, identify)\n",
    "    dx = np.outer([1, 2, 1], [-1, 0, 1]) / 8.0  # Sobel filter\n",
    "    dy = dx.T\n",
    "    c, s = tf.cos(angle), tf.sin(angle)\n",
    "    kernel = tf.stack([identify, c*dx-s*dy, s*dx+c*dy], -1)[:, :, None, :]\n",
    "    kernel = tf.repeat(kernel, self.channel_n, 2)\n",
    "    y = tf.nn.depthwise_conv2d(x, kernel, [1, 1, 1, 1], 'SAME')\n",
    "    return y\n",
    "\n",
    "  @tf.function\n",
    "  def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
    "    pre_life_mask = get_living_mask(x)\n",
    "\n",
    "    y = self.perceive(x, angle)\n",
    "    dx = self.dmodel(y)*step_size\n",
    "    if fire_rate is None:\n",
    "      fire_rate = self.fire_rate\n",
    "    update_mask = tf.random.uniform(tf.shape(x[:, :, :, :1])) <= fire_rate\n",
    "    x += dx * tf.cast(update_mask, tf.float32)\n",
    "\n",
    "    post_life_mask = get_living_mask(x)\n",
    "    life_mask = pre_life_mask & post_life_mask\n",
    "    return x * tf.cast(life_mask, tf.float32)\n",
    "\n",
    "\n",
    "CAModel().dmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7367ebc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFAAAABQCAIAAAABc2X6AAACHElEQVR4nO2bPVIDMQyFZYYibTquQcq9Aseg5DwpcwyukBKuQUdLtxT2EDmyd/1vxn6vyqw3cZRvZEvPG7WuK82kh95foLUQ8OhCwKMLAY8uBDy6EPDoQsCj67HlZEqpuyshvRp/V35vB8L1tV7f/15repqb5M/vV8tLkdlBuK0MPc35+anBjCDcQ9tsdfaW8t5AuLHeXu8uqM8v542lduPpCKuWvrRvNfZR3VbaN5+OcLcc5lTXjysR0c83EdHheHutdTgSkTott/uRw+FqRJivsV62evS0kF0/89ob3VK0muawo+/hudpE0xGuvg+bvZf3wKKz5aM7n5ZdV09HuJvjYVixVVquyTU0HeFGtbTMZGvU41ftZD5q6RB16Ja0Ymmbd6HSilVTwmZKef6wuTLD08pSIuFYh8m6nzkeaV5H+LxS0xGOrrSkLyVpe0+JhJulr1gdsoe/o3Nm51Lhmo5wdA47nMfzhez9c3uP9Z0zBHEWtRcI7yiP8PlyPxrQ8fg4+wjLUXMPVukQpRKWDNkpkYOGzD2xPocLjkeEsiotw02cAPLcjn02Q3og/LpxrUE4XImelqyo5Lqd+NyNz6ku5GBPR7hYP+zocgt1RdZnwvGIVTFfmv/2vrPC/yAQzlO9Z+rgaSWq+tlSr5rZJxAuLc02ZE9u45BPR7jKycO2j9n3P+kgPLqmI4yARxcCHl0IeHQh4NGFgEfXL3YSHOjdIjYlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_emoji(emoji,max_size=TARGET_SIZE):\n",
    "  #gotem this just loads a picture of mario now lmao\n",
    "  img = plt.imread(\"Mario.png\")\n",
    "  img = np.float32(img)\n",
    "  # premultiply RGB by Alpha\n",
    "  img[..., :3] *= img[..., 3:]\n",
    "  return img\n",
    "\n",
    "target_img = load_emoji(TARGET_EMOJI)\n",
    "imshow(zoom(to_rgb(target_img), 2), fmt='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db8f3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This pool class isnt super necessary\n",
    "\n",
    "#@title Train Utilities (SamplePool, Model Export, Damage)\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "\n",
    "class SamplePool:\n",
    "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
    "    self._parent = _parent\n",
    "    self._parent_idx = _parent_idx\n",
    "    self._slot_names = slots.keys()\n",
    "    self._size = None\n",
    "    for k, v in slots.items():\n",
    "      if self._size is None:\n",
    "        self._size = len(v)\n",
    "      assert self._size == len(v)\n",
    "      setattr(self, k, np.asarray(v))\n",
    "\n",
    "  def sample(self, n):\n",
    "    idx = np.random.choice(self._size, n, False)\n",
    "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
    "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
    "    return batch\n",
    "\n",
    "  def commit(self):\n",
    "    for k in self._slot_names:\n",
    "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
    "\n",
    "@tf.function\n",
    "def make_circle_masks(n, h, w):\n",
    "  x = tf.linspace(-1.0, 1.0, w)[None, None, :]\n",
    "  y = tf.linspace(-1.0, 1.0, h)[None, :, None]\n",
    "  center = tf.random.uniform([2, n, 1, 1], -0.5, 0.5)\n",
    "  r = tf.random.uniform([n, 1, 1], 0.1, 0.4)\n",
    "  x, y = (x-center[0])/r, (y-center[1])/r\n",
    "  mask = tf.cast(x*x+y*y < 1.0, tf.float32)\n",
    "  return mask\n",
    "\n",
    "def export_model(ca, base_fn):\n",
    "  ca.save_weights(base_fn)\n",
    "\n",
    "  cf = ca.call.get_concrete_function(\n",
    "      x=tf.TensorSpec([None, None, None, CHANNEL_N]),\n",
    "      fire_rate=tf.constant(0.5),\n",
    "      angle=tf.constant(0.0),\n",
    "      step_size=tf.constant(1.0))\n",
    "  cf = convert_to_constants.convert_variables_to_constants_v2(cf)\n",
    "  graph_def = cf.graph.as_graph_def()\n",
    "  graph_json = MessageToDict(graph_def)\n",
    "  graph_json['versions'] = dict(producer='1.14', minConsumer='1.14')\n",
    "  model_json = {\n",
    "      'format': 'graph-model',\n",
    "      'modelTopology': graph_json,\n",
    "      'weightsManifest': [],\n",
    "  }\n",
    "  with open(base_fn+'.json', 'w') as f:\n",
    "    json.dump(model_json, f)\n",
    "\n",
    "def generate_pool_figures(pool, step_i):\n",
    "  tiled_pool = tile2d(to_rgb(pool.x[:49]))\n",
    "  fade = np.linspace(1.0, 0.0, 72)\n",
    "  ones = np.ones(72) \n",
    "  tiled_pool[:, :72] += (-tiled_pool[:, :72] + ones[None, :, None]) * fade[None, :, None] \n",
    "  tiled_pool[:, -72:] += (-tiled_pool[:, -72:] + ones[None, :, None]) * fade[None, ::-1, None]\n",
    "  tiled_pool[:72, :] += (-tiled_pool[:72, :] + ones[:, None, None]) * fade[:, None, None]\n",
    "  tiled_pool[-72:, :] += (-tiled_pool[-72:, :] + ones[:, None, None]) * fade[::-1, None, None]\n",
    "  imwrite('train_log/%04d_pool.jpg'%step_i, tiled_pool)\n",
    "\n",
    "def visualize_batch(x0, x, step_i):\n",
    "  vis0 = np.hstack(to_rgb(x0).numpy())\n",
    "  vis1 = np.hstack(to_rgb(x).numpy())\n",
    "  vis = np.vstack([vis0, vis1])\n",
    "  imwrite('train_log/batches_%04d.jpg'%step_i, vis)\n",
    "  print('batch (before/after):')\n",
    "  imshow(vis)\n",
    "\n",
    "def plot_loss(loss_log):\n",
    "  pl.figure(figsize=(10, 4))\n",
    "  pl.title('Loss history (log10)')\n",
    "  pl.plot(np.log10(loss_log), '.', alpha=0.1)\n",
    "  pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da8705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c44e7368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#@title Initialize Training { vertical-output: true}\n",
    "\n",
    "p = TARGET_PADDING\n",
    "pad_target = tf.pad(target_img, [(p, p), (p, p), (0, 0)])\n",
    "h, w = pad_target.shape[:2]\n",
    "seed = np.zeros([h, w, CHANNEL_N], np.float32)\n",
    "seed[h//2, w//2, 3:] = 1.0\n",
    "\n",
    "def loss_f(x):\n",
    "  return tf.reduce_mean(tf.square(to_rgba(x)-pad_target), [-2, -3, -1])\n",
    "\n",
    "ca = CAModel()\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "lr = 2e-3\n",
    "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [2000], [lr, lr*0.1])\n",
    "trainer = tf.keras.optimizers.Adam(lr_sched)\n",
    "\n",
    "loss0 = loss_f(seed).numpy()\n",
    "pool = SamplePool(x=np.repeat(seed[None, ...], POOL_SIZE, 0))\n",
    "\n",
    "!mkdir -p train_log && rm -f train_log/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f82ef53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch (before/after):\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " step: 4, log10(loss): -1.546"
     ]
    }
   ],
   "source": [
    "#@title Training Loop {vertical-output: true}\n",
    "\n",
    "@tf.function\n",
    "def train_step(x):\n",
    "  iter_n = tf.random.uniform([], 64, 96, tf.int32)\n",
    "  with tf.GradientTape() as g:\n",
    "    for i in tf.range(iter_n):\n",
    "      x = ca(x)\n",
    "    loss = tf.reduce_mean(loss_f(x))\n",
    "  grads = g.gradient(loss, ca.weights)\n",
    "  grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
    "  trainer.apply_gradients(zip(grads, ca.weights))\n",
    "  return x, loss\n",
    "\n",
    "for i in range(8000+1):\n",
    "  if USE_PATTERN_POOL:\n",
    "    batch = pool.sample(BATCH_SIZE)\n",
    "    x0 = batch.x\n",
    "    loss_rank = loss_f(x0).numpy().argsort()[::-1]\n",
    "    x0 = x0[loss_rank]\n",
    "    x0[:1] = seed\n",
    "    if DAMAGE_N:\n",
    "      damage = 1.0-make_circle_masks(DAMAGE_N, h, w).numpy()[..., None]\n",
    "      x0[-DAMAGE_N:] *= damage\n",
    "  else:\n",
    "    x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
    "\n",
    "  x, loss = train_step(x0)\n",
    "\n",
    "  if USE_PATTERN_POOL:\n",
    "    batch.x[:] = x\n",
    "    batch.commit()\n",
    "\n",
    "  step_i = len(loss_log)\n",
    "  loss_log.append(loss.numpy())\n",
    "  \n",
    "  if step_i%10 == 0:\n",
    "    generate_pool_figures(pool, step_i)\n",
    "  if step_i%100 == 0:\n",
    "    clear_output()\n",
    "    visualize_batch(x0, x, step_i)\n",
    "    plot_loss(loss_log)\n",
    "    export_model(ca, 'train_log/%04d'%step_i)\n",
    "\n",
    "  print('\\r step: %d, log10(loss): %.3f'%(len(loss_log), np.log10(loss)), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa351c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
